{
 "metadata": {
  "name": "",
  "signature": "sha256:c92f7a54101fa062820cdb9eed2c5fbf8fcef31e8e77b7c0068da41ae9133162"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using a Naive Bayesian Classifier to Reduce Spam in Mozilla SUMO Projects\n",
      "=========================================================================\n",
      "Spam comes from two primary sources, bots and people.  \n",
      "Fooling bots is surprisingly easy. Other projects, such as the marketplace have had success with invisible inputs in forms. If the bot changes the input, then the report is rejected. Input doesn't use this, but it could.\n",
      "Preventing human spam is harder. You can throttle responses, but that's not terribly effective either.\n",
      "My idea is to have machine learning classify spam messages. I propose using a Naive Bayesian Classifier.\n",
      "\n",
      "What is a Bayes Theorem?\n",
      "------------------------\n",
      "Bayes Theorem is the cornerstone of modern statistics. Bayes Theorem relies on using prior knowledge to update a belief about a probability. A Bayesian approach is probabilistic, we determine what the probability that a message is spam.  \n",
      "\n",
      "Bayes Theorem states:  \n",
      "$$p(a|b) = \\frac{p(b|a) \\cdot p(a)}{p(b)}$$\n",
      "This is read \"The probability of $a$ given be is the probability of $b$ given $a$ times the probability of $a$ over the probability of $b$.\"\n",
      "The $p(a|b)$, is the intersection of the probabilities, that is $p(a) \\cap p(b)$. Note $p(a|b) \\neq p(b|a)$.\n",
      "\n",
      "What are the advantages and disadvantages of using this sort of classifier?\n",
      "---------------------------------------------------------\n",
      "\n",
      "*Pros:*\n",
      "* A Naive Bayesian Classifier is great for non-numeric data.\n",
      "* It can easily be implemented easily and is very effective.\n",
      "\n",
      "\n",
      "*Cons:*\n",
      "* This type of classifier is inherently stateful, and requires a database of training data.\n",
      "* It can recquire a large series of training data.\n",
      "* Training is an expensive one time cost.\n",
      "\n",
      "\n",
      "How do we use Bayes Theorem to classify spam?\n",
      "---------------------------------------------\n",
      "\n",
      "Say there are 100 words used in some number of messages. 20 of these words are in spam messages. A word $w$ appears in a message which is known to be spam 3 times, and it also appears in a meassage known to be ham (that is, a legitimate message that is not spam) 1 time. We can use Bayes theorem to determine whether that message is spam.\n",
      "\n",
      "\n",
      "<table>\n",
      "<tr> <th>      </th> <th>Spam</th> <th> Ham </th> <th>Total</th> </tr>\n",
      "<tr> <th>Totals  </th> <td> 20 </td> <td> 80  </td> <td> 100 </td> </tr>\n",
      "<tr> <th>Word $w$</th> <td> 3  </td> <td> 1   </td> <td> 4   </td> </tr>\n",
      "</table>\n",
      "\n",
      "\n",
      "First let's rephrase Bayes theorem in terms of this example.\n",
      "\n",
      "\n",
      "$$p(\\mathrm{Spam} | w) = \\frac{p(w | \\mathrm{Spam}) \\cdot p(\\mathrm{Spam})}{p(w)}$$\n",
      "\n",
      "\n",
      "\n",
      "To calculate the probability of $w$, $p(w)$, Take $\\frac{\\mathrm{occurences of } w}{\\mathrm{total} \\mathrm{number} \\mathrm{of} \\mathrm{words}}$, which is  $\\frac{3}{100}$ or $0.03$.\n",
      "\n",
      "To calculate the probability of Spam we do something very similar. $\\frac{\\mathrm{occurences} \\mathrm{of} \\mathrm{Spam}}{\\mathrm{total} \\mathrm{number} \\mathrm{of} \\mathrm{words}}$, which is  $\\frac{20}{100}$ or $0.20$.\n",
      "\n",
      "\n",
      "Calculating the probability of $w$ given Spam is again similar.  $\\frac{\\mathrm{occurences} \\mathrm{of}w}{\\mathrm{total} \\mathrm{number} \\mathrm{of} \\mathrm{Spam}}$, which is  $\\frac{3}{20}$ or $0.15$.\n",
      "\n",
      "Put all of this together and you get: \n",
      "\n",
      "\n",
      "$$p(\\mathrm{Spam} | w) = \\frac{0.15 \\cdot 0.20}{0.03} = 1$$\n",
      "\n",
      "\n",
      "Note that this isn't our final probability. We need to determine the ratio of the probability that the word is spam over the probability that the word is ham. In other words:\n",
      "\n",
      "\n",
      "$$\\frac{p(\\mathrm{Spam}|w)}{p(\\mathrm{Ham}|w)}$$\n",
      "\n",
      "\n",
      "Calculating $p(\\mathrm{Ham}|w)$ is very similar, and we get:\n",
      "\n",
      "\n",
      "$$p(\\mathrm{Ham} | w) = \\frac{0.0125 \\cdot 0.80}{0.03} = 0.33333...$$\n",
      "\n",
      "\n",
      "As a result we can conclude that it is three times as likely that a message with this word is spam.\n",
      "\n",
      "If we want to include the probabilities of multiple words, say an additional word $w_1$ we may express that as $p(\\mathrm{Spam}|w \\cap w_1)$. Then Bayes Theorem can be transformed into:\n",
      "\n",
      "\n",
      "$$p(\\mathrm{Spam}|w \\cap w_1) = \\frac{p(w | \\mathrm{Spam}) \\cdot p(w_1 | \\mathrm{Spam}) \\cdot p(\\mathrm{Spam})}{p(w) \\cdot p(w_1)}$$\n",
      "\n",
      "\n",
      "We can see that if we have $n$ words the equation will be:\n",
      "\n",
      "\n",
      "$$p(\\mathrm{Spam}|w_1 \\ldots w_n) = p(Spam) \\cdot \\prod_{i=1}^{n} \\frac{p(\\mathrm{Spam}|w_i)}{p(w_i)}$$\n",
      "\n",
      "\n",
      "In python this can be expressed as the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sample data from the api, de-jsonified\n",
      "response = {\n",
      "    u'category': u'',\n",
      "    u'url_domain': u'google.com',\n",
      "    u'product': u'Firefox',\n",
      "    u'user_agent':\n",
      "    u'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0',\n",
      "    u'organic': True, u'description':\n",
      "    u'i love you Firefox',\n",
      "    u'campaign': u'',\n",
      "    u'created': u'2014-07-31T13:43:49',\n",
      "    u'locale': u'ar',\n",
      "    u'source': u'',\n",
      "    u'version': u'31.0',\n",
      "    u'has_email': False,\n",
      "    u'platform': u'Windows 7',\n",
      "    u'id': 4542693,\n",
      "    u'happy': True\n",
      "}\n",
      "\n",
      "def is_spam(self, response):                                                       \n",
      "    \"\"\"Get the probability that a response is spam. response is a dict\"\"\"          \n",
      "    session = self.sessionFactory()                                                \n",
      "    query = session.query(WordProbability).filter(                                 \n",
      "        WordProbability.word == '*')                                               \n",
      "    # If this doesn't exist then the DB hasn't been trained                        \n",
      "    total = query.one()                                                            \n",
      "    pSpam = float(total.numSpam) / float(total.numTotal)                           \n",
      "    # Since spam and ham are independant events                                    \n",
      "    pHam = 1.0 - pSpam                                                             \n",
      "    pSpamGivenWord = pSpam                                                         \n",
      "    pHamGivenWord = pHam                                                           \n",
      "    for description in response['description'].split(' '):                         \n",
      "        if description == '*':                                                     \n",
      "            continue                                                               \n",
      "        try:                                                                       \n",
      "            query = session.query(WordProbability).filter(                         \n",
      "                WordProbability.word == description)                               \n",
      "            word = query.one()                                                     \n",
      "        except NoResultFound, e:                                                   \n",
      "            continue                                                               \n",
      "        pWord = float(word.numTotal) / float(total.numTotal)                       \n",
      "        pWordGivenSpam = float(word.numSpam) / float(total.numSpam)                \n",
      "        pWordGivenHam = float(                                                     \n",
      "            word.numTotal - word.numSpam) / float(total.numTotal - total.numSpam)\n",
      "                                                                                   \n",
      "        pSpamGivenWord *= pWordGivenSpam / pWord                                   \n",
      "        pHamGivenWord *= pWordGivenHam / pWord                                     \n",
      "    return pSpamGivenWord / (pSpamGivenWord + pHamGivenWord)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Some statistics about the effectiveness of the current implementation:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "When testing against the training corpus:\n",
      "* Processed 484 messages  \n",
      "* True positives 21  \n",
      "* False positives 3  \n",
      "* True negatives 447  \n",
      "* False negatives 13  \n",
      "\n",
      "\n",
      "\n",
      "When testing against the control corpus:\n",
      "* processed 485 messages  \n",
      "* True positives 1  \n",
      "* False positives 2  \n",
      "* True negatives 448  \n",
      "* False negatives 34  \n",
      "\n",
      "Future Exploration:\n",
      "-------------------\n",
      "What happens when we train it one API data which it classified as spam?\n",
      "What leaks through?\n",
      "\n",
      "Alternatives to a Naive Bayesian Classifier\n",
      "-------------------------------------------\n",
      "K Nearest Nieghbors is another machine learning technique\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}